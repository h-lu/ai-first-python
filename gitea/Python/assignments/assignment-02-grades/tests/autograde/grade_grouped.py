#!/usr/bin/env python3
"""
æŒ‰åˆ†ç»„è®¡ç®—ç¼–ç¨‹é¢˜å¾—åˆ†ï¼ˆpytest JUnit XMLï¼‰

- core ç»„æ»¡åˆ† 10
- edge ç»„æ»¡åˆ† 5
- æ€»åˆ†ä¸ºå„ç»„å¾—åˆ†ä¹‹å’Œï¼ˆæ»¡åˆ† 15ï¼‰
"""

import argparse
import xml.etree.ElementTree as ET
import json
import os
import re
import sys
from glob import glob


def parse_junit_files(junit_dir):
    """è§£æžç›®å½•ä¸‹æ‰€æœ‰ JUnit XML æŠ¥å‘Š"""
    results = []
    xml_files = glob(os.path.join(junit_dir, "TEST-*.xml")) or glob(
        os.path.join(junit_dir, "*.xml")
    )

    for xml_file in xml_files:
        try:
            root = ET.parse(xml_file).getroot()
            for testsuite in root.iter("testsuite"):
                for testcase in testsuite.iter("testcase"):
                    classname = testcase.get("classname", "")
                    name = testcase.get("name", "")
                    # æ³¨æ„ï¼šElement æ²¡æœ‰å­å…ƒç´ æ—¶ bool å€¼ä¸º Falseï¼Œæ‰€ä»¥ç”¨ find() is not None
                    failed = testcase.find("failure") is not None or testcase.find("error") is not None
                    skipped = testcase.find("skipped") is not None
                    results.append(
                        {
                            "classname": classname,
                            "name": name,
                            "passed": not failed and not skipped,
                            "skipped": skipped,
                        }
                    )
        except Exception as e:
            print(f"Error parsing {xml_file}: {e}", file=sys.stderr)
    return results


def load_groups_config(groups_file):
    """åŠ è½½æµ‹è¯•åˆ†ç»„é…ç½®"""
    if not os.path.exists(groups_file):
        return {
            "groups": {
                "core": {"pattern": "core", "max_score": 10},
                "edge": {"pattern": "edge", "max_score": 5},
            },
            "fallback_group": "core",
        }

    with open(groups_file, "r", encoding="utf-8") as f:
        return json.load(f)


def categorize_test(classname, groups_config):
    """æ ¹æ® classname å°†æµ‹è¯•åˆ†ç±»åˆ°å¯¹åº”çš„ç»„"""
    for group_name, group_info in groups_config.get("groups", {}).items():
        pattern = group_info.get("pattern", "")
        if re.search(pattern, classname, re.IGNORECASE):
            return group_name
    return groups_config.get("fallback_group", "core")


def calculate_grouped_score(test_results, groups_config):
    """æŒ‰åˆ†ç»„è®¡ç®—å¾—åˆ†"""
    groups = groups_config.get("groups", {})
    group_stats = {}

    for group_name, group_info in groups.items():
        group_stats[group_name] = {
            "passed": 0,
            "total": 0,
            "max_score": group_info.get("max_score", 0),
            "tests": [],
        }

    for test in test_results:
        group = categorize_test(test["classname"], groups_config)
        if group not in group_stats:
            group = groups_config.get("fallback_group", "core")

        group_stats[group]["total"] += 1
        if test["passed"]:
            group_stats[group]["passed"] += 1
        else:
            group_stats[group]["tests"].append(f"{test['classname']}.{test['name']}")

    total_score = 0
    total_max = 0
    group_scores = {}

    for group_name, stats in group_stats.items():
        total_max += stats["max_score"]
        if stats["total"] > 0:
            pass_rate = stats["passed"] / stats["total"]
            group_score = pass_rate * stats["max_score"]
        else:
            group_score = 0

        group_scores[group_name] = {
            "passed": stats["passed"],
            "total": stats["total"],
            "max_score": stats["max_score"],
            "score": round(group_score, 2),
            "failed_tests": stats["tests"][:10],
        }
        total_score += group_score

    return {
        "total_score": round(total_score, 2),
        "max_score": total_max,
        "groups": group_scores,
    }


def main():
    parser = argparse.ArgumentParser(description="Grade programming assignments with test groups")
    parser.add_argument("--junit-dir", required=True, help="Directory containing JUnit XML files")
    parser.add_argument("--groups", default="test_groups.json", help="Test groups configuration file")
    parser.add_argument("--out", default="grade.json", help="Output JSON file")
    parser.add_argument("--summary", default="summary.md", help="Output summary markdown file")
    args = parser.parse_args()

    test_results = parse_junit_files(args.junit_dir)

    if not test_results:
        print("Warning: No test results found", file=sys.stderr)
        grade_data = {
            "total_score": 0,
            "max_score": 0,
            "groups": {},
            "error": "No test results found",
        }
    else:
        groups_config = load_groups_config(args.groups)
        
        # Debug: æ˜¾ç¤ºæµ‹è¯•åˆ†ç±»
        print(f"ðŸ“ Found {len(test_results)} tests:")
        for test in test_results:
            group = categorize_test(test["classname"], groups_config)
            status = "âœ…" if test["passed"] else "âŒ"
            print(f"  {status} [{group}] {test['classname']}.{test['name']}")
        
        grade_data = calculate_grouped_score(test_results, groups_config)

    with open(args.out, "w", encoding="utf-8") as f:
        json.dump(grade_data, f, ensure_ascii=False, indent=2)

    with open(args.summary, "w", encoding="utf-8") as f:
        f.write("# ç¼–ç¨‹æµ‹è¯•æˆç»©æŠ¥å‘Š\n\n")
        f.write(f"**æ€»åˆ†ï¼š{grade_data['total_score']:.2f} / {grade_data['max_score']}**\n\n")
        f.write("## åˆ†ç»„å¾—åˆ†\n\n")
        f.write("| åˆ†ç»„ | é€šè¿‡ | æ€»æ•° | å¾—åˆ† | æ»¡åˆ† |\n")
        f.write("|------|------|------|------|------|\n")
        for group_name, group_info in grade_data.get("groups", {}).items():
            f.write(
                f"| {group_name} | {group_info['passed']} | {group_info['total']} | "
                f"{group_info['score']:.2f} | {group_info['max_score']} |\n"
            )

        all_failed = []
        for group_info in grade_data.get("groups", {}).values():
            all_failed.extend(group_info.get("failed_tests", []))
        if all_failed:
            f.write("\n## æœªé€šè¿‡çš„æµ‹è¯•\n\n")
            for test in all_failed[:20]:
                f.write(f"- {test}\n")
            if len(all_failed) > 20:
                f.write(f"\n... è¿˜æœ‰ {len(all_failed) - 20} ä¸ªæœªé€šè¿‡çš„æµ‹è¯•\n")

    print(f"Grading complete: {grade_data['total_score']:.2f}/{grade_data['max_score']}")


if __name__ == "__main__":
    main()

