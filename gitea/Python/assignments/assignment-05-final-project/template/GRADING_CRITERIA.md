# 期末项目评分标准

> 💯 **总分**：25 分  
> 本文档详细说明评分系统如何评估你的项目，请仔细阅读。

---

## 总览

| 评估维度 | 分值 | 评估内容 |
|---------|------|---------|
| 📄 文档质量 | **8 分** | REPORT.md (5分) + CHANGELOG.md (3分) |
| ⚡ 功能表现 | **12 分** | 运行 manifest.yaml 中的命令，评估输出 |
| 🔧 代码质量 | **5 分** | 评估代码结构、可读性、安全性 |

---

## ⚠️ 必选功能（重要！）

以下 5 项功能是**必选要求**，缺少任何一项都会严重影响得分：

| 必选功能 | 说明 | 缺失后果 |
|---------|------|---------|
| **LLM 集成** | 必须调用 DeepSeek/OpenAI API | ❌ 功能分最高 5/12，代码结构最高 1/2 |
| 外部数据交互 | 文件读写或其他 API 调用 | 影响核心功能评分 |
| 数据处理逻辑 | 有实质性数据操作，不只是透传 | 影响核心功能评分 |
| 用户交互 | CLI (argparse) 或 Web (Streamlit) | 影响用户体验评分 |
| 错误处理 | 无效输入不会导致程序崩溃 | 影响错误处理评分 |

> 🚨 **LLM 集成是最重要的必选项！** 没有 LLM 功能的项目将被视为不符合基本要求。

---

## 📄 文档质量评分（8 分）

### REPORT.md 反思报告（5 分）

| 评分项 | 分值 | 满分标准 | 零分情况 |
|-------|------|---------|---------|
| **项目定位** | 1 分 | 清楚说明解决什么问题、目标用户、为什么值得做 | 只说"完成作业"或占位符 `[在此填写]` |
| **技术决策** | 2 分 | 有技术选型对比表、选择理由、**有效的 Prompt 示例**、AI 帮不了的思考 | 模板 `[例：JSON]` 未替换，或"与 AI 协作"部分空白 |
| **迭代成长** | 1 分 | 描述真实遇到的挑战、尝试的方案、学到的经验 | 空洞的占位符或流水账 |
| **自我反思** | 1 分 | 诚实评价项目优缺点，有具体的遗憾点 | 套话"收获很大"或空白 |

#### 技术决策详细说明（2分项）

这一项评估两部分内容：

**1. 技术选型（1分）**
- 填写技术选型表格（数据存储、用户界面、LLM提供商等）
- 说明考虑过的替代方案和选择理由
- 描述最难的技术决策

**2. 与 AI 协作（1分）**
- 展示一个你写得好的 Prompt 示例
- 解释为什么这个 Prompt 有效
- 说明 AI 帮不了、必须你自己思考的地方

### CHANGELOG.md 版本记录（3 分）

| 分数 | 标准 |
|------|------|
| **3 分** | 3+ 个版本，每版有实质变化，日期真实（如 2024-12-06），详细描述改动原因 |
| **2 分** | 2 个版本，能看出迭代过程 |
| **1 分** | 1 个版本或记录过于简略 |
| **0 分** | 无记录，或日期是 `YYYY-MM-DD`、内容是 `XXX功能` 等占位符 |

---

## ⚡ 功能表现评分（12 分）

评测系统会运行你在 `manifest.yaml` 中声明的命令，根据输出评分。

### 核心功能（4 分）

| 分数 | 标准 |
|------|------|
| **4 分** | demo 命令展示 5+ 个功能，功能间有数据流转（添加→查询→分析→导出），LLM 是核心流程，输出有格式化 |
| **3 分** | 功能完整，**包含有效的 LLM 集成**，输出正确清晰 |
| **2 分** | 主要功能可用，但 **LLM 功能缺失或无效**（这是缺少 LLM 时的最高分！） |
| **1 分** | 部分功能可用，有明显 bug |
| **0 分** | 输出模板提示"🚧 项目待实现"，或只有 --help |

### LLM 集成（3 分）

> ⚠️ **这是必选功能！** 此项为 0 分意味着项目不符合基本要求。

| 分数 | 标准 |
|------|------|
| **3 分** | LLM 基于用户数据做个性化分析，输出 50 字以上有实质内容，去掉 LLM 产品价值显著降低 |
| **2 分** | LLM 调用成功，返回有意义的内容，与用户数据相关 |
| **1 分** | LLM 返回通用模板内容，或输出过短（<20字），与用户数据无关 |
| **0 分** | 无 LLM 调用，或完全失败 ❌ |

### 错误处理（3 分）

| 分数 | 标准 |
|------|------|
| **3 分** | 全部无 Traceback，有自定义友好提示（如"错误：日期格式无效，请使用 YYYY-MM-DD"） |
| **2 分** | 无 Traceback 崩溃，有错误提示（可能是 argparse 默认或简单 Error） |
| **1 分** | 有 1-2 个命令仍导致 Traceback，或只打印默认错误 |
| **0 分** | 无效输入导致 Python Traceback 崩溃 |

### 用户体验（2 分）

| 分数 | 标准 |
|------|------|
| **2 分** | --help 有使用示例，输出有格式化（表格/分隔线/emoji），有成功/失败状态提示 |
| **1 分** | 基本可用，有 --help 帮助信息 |
| **0 分** | 难以使用，无帮助信息，输出混乱 |

---

## 🔧 代码质量评分（5 分）

### 代码结构（2 分）

| 分数 | 标准 |
|------|------|
| **2 分** | 结构清晰，有多个模块（如 storage.py, llm.py, main.py），**包含 LLM 调用代码** |
| **1 分** | 有业务代码但都在一个文件，或**缺少 LLM 调用代码** |
| **0 分** | 模板代码未修改，只有 `print("🚧 项目待实现")` |

### 代码可读性（2 分）

| 分数 | 标准 |
|------|------|
| **2 分** | 变量命名规范（如 diary_content），关键位置有注释 |
| **1 分** | 变量名基本可理解，有部分注释 |
| **0 分** | 变量名无意义（如 a, b, x），无注释 |

### 安全性（1 分）

| 分数 | 标准 |
|------|------|
| **1 分** | 使用 `os.getenv()` 获取 API Key，有 `.env.example` 文件 |
| **0 分** | API Key 硬编码在代码中（如 `api_key = "sk-xxx"`） |

---

## 🎯 得分指南

### 满分项目特征（25 分）

- ✅ REPORT.md 有真实的项目思考，技术决策有对比，与 AI 协作有具体例子
- ✅ CHANGELOG.md 有 3+ 版本，清晰记录迭代过程
- ✅ manifest.yaml 命令都能成功运行，输出有意义
- ✅ **LLM 功能明显提升产品价值**
- ✅ 错误处理完善，用户体验好
- ✅ 代码结构清晰，多模块分工，安全处理 API Key

### 及格项目特征（15 分左右）

- ✅ 文档基本填写，有一定内容
- ✅ 核心功能可以运行
- ✅ **有 LLM 功能但可能不够完善**
- ⚠️ 错误处理一般
- ⚠️ 代码组织一般

### 不及格项目特征（<12 分）

- ❌ 文档是模板占位符
- ❌ **没有 LLM 功能**（直接不满足必选要求）
- ❌ 功能无法运行或输出模板提示
- ❌ 代码是模板原样

---

## 常见扣分点

| 问题 | 影响 |
|-----|------|
| 文档是占位符（`[在此填写]`、`YYYY-MM-DD`、`XXX功能`） | 对应评分项 0 分 |
| 没有 LLM 功能 | 功能分最高 5/12，代码结构最高 1/2 |
| 命令输出"🚧 项目待实现" | 核心功能 0 分 |
| manifest.yaml 未修改（项目名是"你的项目名称"） | 所有功能分 0 分 |
| API Key 硬编码 | 安全性 0 分 |
| 无效输入导致 Traceback | 错误处理减分 |

---

## 自检清单

提交前请确认：

- [ ] `manifest.yaml` 已修改，项目名称和描述是真实的
- [ ] 所有 demo 命令都能成功运行
- [ ] **至少有一个命令展示 LLM 功能**
- [ ] 错误处理命令不会导致程序崩溃
- [ ] `REPORT.md` 所有部分都已填写，无占位符
- [ ] `CHANGELOG.md` 有真实日期和具体内容
- [ ] API Key 使用环境变量，有 `.env.example` 文件
- [ ] 代码有合理的模块划分

---

> 💡 **提示**：评分系统使用 LLM 评估，它会仔细阅读你的文档和代码。真实、具体的内容会得到认可，模板和套话会被识别为未完成。
