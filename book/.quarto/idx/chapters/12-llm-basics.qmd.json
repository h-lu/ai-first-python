{"title":"LLM 应用开发","markdown":{"headingText":"LLM 应用开发","headingAttr":{"id":"sec-llm","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n::: {.callout-note}\n## 本章概要\n- **课时**：2课时（第12周）\n- **目标**：深入 LLM API 使用，掌握 Prompt Engineering\n:::\n\n## 学习目标\n\n完成本章后，你将能够：\n\n1. 使用 OpenAI 库实现多轮对话\n2. 设计有效的 System Prompt\n3. 应用 Prompt Engineering 技巧\n4. 实现流式输出\n\n---\n\n## 从单轮到多轮对话\n\n### 对话历史的重要性\n\n```{mermaid}\nflowchart TD\n    A[\"用户: 我叫张三\"] --> B[\"AI: 你好张三！\"]\n    B --> C[\"用户: 我今年20岁\"]\n    C --> D[\"AI: 了解，20岁很年轻\"]\n    D --> E[\"用户: 我是谁？\"]\n    E --> F{\"有对话历史?\"}\n    F -->|有| G[\"AI: 你是张三，20岁\"]\n    F -->|无| H[\"AI: 我不知道你是谁\"]\n```\n\n### 使用 OpenAI 库实现多轮对话\n\n```{python}\n#| eval: false\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclass ChatBot:\n    \"\"\"使用 OpenAI 库的多轮对话机器人\"\"\"\n    \n    def __init__(self, system_prompt=\"你是一个有帮助的助手。\"):\n        self.client = OpenAI(\n            api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n            base_url=\"https://api.deepseek.com\"\n        )\n        self.model = \"deepseek-chat\"\n        self.messages = [\n            {\"role\": \"system\", \"content\": system_prompt}\n        ]\n    \n    def chat(self, user_message):\n        \"\"\"发送消息并获取回复\"\"\"\n        # 添加用户消息到历史\n        self.messages.append({\"role\": \"user\", \"content\": user_message})\n        \n        try:\n            response = self.client.chat.completions.create(\n                model=self.model,\n                messages=self.messages\n            )\n            \n            reply = response.choices[0].message.content\n            # 添加助手回复到历史\n            self.messages.append({\"role\": \"assistant\", \"content\": reply})\n            return reply\n            \n        except Exception as e:\n            return f\"错误: {e}\"\n    \n    def clear_history(self):\n        \"\"\"清空对话历史，保留 system prompt\"\"\"\n        self.messages = self.messages[:1]\n\n# 使用示例\n# bot = ChatBot(\"你是一个友好的中文助手\")\n# print(bot.chat(\"我叫小明\"))\n# print(bot.chat(\"我刚才说我叫什么？\"))\n```\n\n### 对话历史管理\n\n```{mermaid}\nflowchart LR\n    A[\"messages 列表\"] --> B[\"system: 角色设定\"]\n    B --> C[\"user: 消息1\"]\n    C --> D[\"assistant: 回复1\"]\n    D --> E[\"user: 消息2\"]\n    E --> F[\"assistant: 回复2\"]\n    F --> G[\"...\"]\n```\n\n::: {.callout-warning}\n## 注意上下文长度限制\n\n**多轮对话的本质**：LLM 本身是**无状态的**，每次 API 调用都是独立的。所谓\"多轮对话\"，实际上是把**完整的对话历史**（所有之前的问答）加上最新输入，一起发送给模型。模型根据这份完整上下文生成回复。\n\n**问题**：随着对话轮次增加，`messages` 列表越来越长，可能超出模型的上下文窗口（如 GPT-3.5 是 4K/16K tokens）。\n\n**常见解决策略**：\n\n| 策略 | 做法 | 适用场景 |\n|------|------|----------|\n| **滑动窗口** | 只保留最近 N 轮对话 | 休闲聊天，不依赖早期信息 |\n| **Token 截断** | 用 `tiktoken` 计算 token 数，超限时删除最早对话 | 需要精确控制成本 |\n| **历史总结** | 用 LLM 总结早期对话，压缩为一条 system 消息 | 长任务对话，需保留关键信息 |\n\n示例（滑动窗口）：\n\n```python\ndef sliding_window(messages, max_turns=5):\n    system_msg = [m for m in messages if m[\"role\"] == \"system\"]\n    conversation = [m for m in messages if m[\"role\"] != \"system\"]\n    return system_msg + conversation[-(max_turns * 2):]  # 保留最近 N 轮\n```\n:::\n\n---\n\n## System Prompt 设计\n\n### 角色定义模板\n\n```{python}\n#| eval: false\n# System Prompt 示例\n\n# 1. 通用助手\nGENERAL_ASSISTANT = \"\"\"\n你是一个友好、专业的中文助手。\n- 回答简洁明了\n- 必要时使用列表和表格\n- 不确定的内容请说明\n\"\"\"\n\n# 2. 代码助手\nCODE_ASSISTANT = \"\"\"\n你是一个 Python 编程助手。\n\n你的任务：\n- 帮助用户解决编程问题\n- 提供代码示例\n- 解释代码原理\n\n规则：\n- 代码使用 Python 3.10+ 语法\n- 添加必要的注释\n- 优先使用标准库\n\"\"\"\n\n# 3. 特定领域专家\nDOMAIN_EXPERT = \"\"\"\n你是一个数据分析专家，精通：\n- Pandas 数据处理\n- Matplotlib 可视化\n- 统计分析方法\n\n回答风格：\n- 先给出简短答案\n- 再解释原理\n- 最后给出代码示例\n\"\"\"\n```\n\n### 好的 System Prompt 特征\n\n| 特征 | 说明 | 示例 |\n|-----|------|------|\n| **明确角色** | 定义 AI 是谁 | \"你是一个 Python 导师\" |\n| **任务边界** | 能做什么，不能做什么 | \"只回答编程问题\" |\n| **输出格式** | 期望的回答格式 | \"使用 Markdown 格式\" |\n| **语言风格** | 正式/友好/专业 | \"用简单易懂的语言\" |\n\n---\n\n## Prompt Engineering 技巧\n\n### Few-shot Prompting\n\n```{mermaid}\nflowchart LR\n    A[\"Few-shot\"] --> B[\"提供示例\"]\n    B --> C[\"引导格式\"]\n    C --> D[\"稳定输出\"]\n```\n\n```{python}\n#| eval: false\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclient = OpenAI(\n    api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n    base_url=\"https://api.deepseek.com\"\n)\n\n# Few-shot 示例：情感分析\nFEW_SHOT_PROMPT = \"\"\"\n分析以下文本的情感（正面/负面/中性）。\n\n示例：\n文本：这个产品太棒了，强烈推荐！\n情感：正面\n\n文本：质量一般，没什么特别的\n情感：中性\n\n文本：非常失望，完全不值这个价格\n情感：负面\n\n现在分析：\n文本：{user_input}\n情感：\n\"\"\"\n\ndef analyze_sentiment(text):\n    \"\"\"使用 Few-shot 进行情感分析\"\"\"\n    prompt = FEW_SHOT_PROMPT.format(user_input=text)\n    \n    response = client.chat.completions.create(\n        model=\"deepseek-chat\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        temperature=0  # 降低随机性\n    )\n    return response.choices[0].message.content\n\n# 使用示例\n# result = analyze_sentiment(\"服务态度很好，下次还会再来\")\n# print(result)  # 输出：正面\n```\n\n### 思维链提示（Chain of Thought）\n\n```{python}\n#| eval: false\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclient = OpenAI(\n    api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n    base_url=\"https://api.deepseek.com\"\n)\n\n# 思维链提示：让 AI 展示推理过程\nCOT_PROMPT = \"\"\"\n请一步步思考并解决这个问题：\n\n问题：小明有 15 个苹果，给了小红 3 个，又买了 7 个，最后还剩多少？\n\n让我们一步步分析：\n1. 初始数量：15 个\n2. 给出后：15 - 3 = 12 个\n3. 购买后：12 + 7 = 19 个\n\n答案：19 个\n\n---\n\n现在请用同样的方法解决：\n问题：{problem}\n\n让我们一步步分析：\n\"\"\"\n\ndef solve_with_cot(problem):\n    \"\"\"使用思维链解决问题\"\"\"\n    prompt = COT_PROMPT.format(problem=problem)\n    \n    response = client.chat.completions.create(\n        model=\"deepseek-chat\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    return response.choices[0].message.content\n\n# 使用示例\n# result = solve_with_cot(\"一个水池有 100 升水，漏掉了 25 升，又加了 40 升，现在有多少升？\")\n# print(result)\n```\n\n\n### 结构化输出（JSON 模式）\n\nDeepSeek 提供了 [JSON Output](https://api-docs.deepseek.com/zh-cn/guides/json_mode) 功能，通过 `response_format` 参数确保模型输出合法的 JSON 字符串。\n\n::: {.callout-note}\n## JSON 模式注意事项\n1. 设置 `response_format={'type': 'json_object'}`\n2. prompt 中**必须包含 `json` 字样**，并给出期望的 JSON 格式样例\n3. 合理设置 `max_tokens`，防止 JSON 被截断\n:::\n\n```{python}\n#| eval: false\nfrom openai import OpenAI\nimport json\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclient = OpenAI(\n    api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n    base_url=\"https://api.deepseek.com\"\n)\n\ndef extract_info(review):\n    \"\"\"从评论中提取结构化信息（使用 JSON 模式）\"\"\"\n    \n    # System prompt 中给出 JSON 格式样例\n    system_prompt = \"\"\"你是一个评论分析助手。请分析用户评论并以 JSON 格式输出。\n\n规则：\n- sentiment 只能是以下三种之一：positive、negative、neutral\n\n输出格式示例：\n{\n    \"sentiment\": \"positive\",\n    \"keywords\": [\"质量好\", \"推荐\"],\n    \"summary\": \"用户对产品满意\"\n}\"\"\"\n    \n    response = client.chat.completions.create(\n        model=\"deepseek-chat\",\n        messages=[\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": f\"请分析这条评论：{review}\"}\n        ],\n        response_format={\"type\": \"json_object\"},  # 启用 JSON 模式\n        temperature=0\n    )\n    \n    # 直接解析 JSON（JSON 模式保证输出合法 JSON）\n    return json.loads(response.choices[0].message.content)\n\n# 使用示例\n# result = extract_info(\"手机很好用，拍照清晰，就是电池不太耐用\")\n# print(result)\n# 输出: {'sentiment': 'positive', 'keywords': ['手机好用', '拍照清晰', '电池不耐用'], 'summary': '用户总体上对手机满意，称赞其好用和拍照清晰，但指出电池续航不足。'}\n```\n\n::: {.callout-important}\n## Prompt 限制 ≠ 保证成功\n即使在 prompt 中要求 `sentiment` 只能是三种值，LLM 仍可能输出其他值（如 `\"mixed\"`）。这是因为 LLM 本质上是概率生成，无法 100% 遵守指令。\n\n**Instructor 的解决方案**：使用 Pydantic 的 `Literal` 类型在**代码层面**强制校验，若输出不符合则自动重试（`max_retries`），从根本上保证输出符合预期。\n:::\n\n::: {.callout-tip}\n## 进阶：使用 Instructor 库处理复杂 JSON\n对于**复杂嵌套结构**或需要**严格类型校验**的场景，推荐使用 [instructor](https://github.com/instructor-ai/instructor) 库。它结合 Pydantic 模型，提供自动验证和失败重试：\n\n```python\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\nfrom typing import Literal\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# 使用 Pydantic 定义输出结构（带类型约束）\nclass ReviewAnalysis(BaseModel):\n    sentiment: Literal[\"positive\", \"negative\", \"neutral\"]  # 严格限制取值\n    keywords: list[str]\n    summary: str\n\n# 用 instructor 包装 OpenAI 客户端\nclient = instructor.from_openai(\n    OpenAI(\n        api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n        base_url=\"https://api.deepseek.com\"\n    )\n)\n\n# 直接返回 Pydantic 对象，自动验证\nresult = client.chat.completions.create(\n    model=\"deepseek-chat\",\n    response_model=ReviewAnalysis,  # 指定输出模型\n    messages=[{\"role\": \"user\", \"content\": \"分析评论：手机很好用，拍照清晰，就是电池不太耐用\"}],\n    temperature=0,   # 稳定输出\n    max_retries=3    # 验证失败时自动重试\n)\n\nprint(result.sentiment)  # positive\nprint(result.keywords)   # ['拍照清晰', '电池不太耐用']\nprint(result.summary)    # 用户整体满意，但对电池续航有所不满\n```\n:::\n\n---\n\n## 实战：智能问答助手\n\n### 使用 OpenAI 库的完整实现\n\n```{python}\n#| eval: false\nfrom openai import OpenAI\nimport os\nimport json\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclass SmartAssistant:\n    \"\"\"智能问答助手（使用 OpenAI 库）\"\"\"\n    \n    def __init__(self, specialty=\"通用\"):\n        self.client = OpenAI(\n            api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n            base_url=\"https://api.deepseek.com\"\n        )\n        self.model = \"deepseek-chat\"\n        \n        self.system_prompt = f\"\"\"\n你是一个{specialty}领域的智能助手。\n\n回答原则：\n1. 先给出简短答案\n2. 再详细解释\n3. 必要时举例说明\n4. 不确定的内容请说明\n\n输出格式：\n- 使用 Markdown 格式\n- 代码使用代码块\n- 重点内容加粗\n\"\"\"\n        \n        self.messages = [\n            {\"role\": \"system\", \"content\": self.system_prompt}\n        ]\n    \n    def ask(self, question):\n        \"\"\"提问\"\"\"\n        self.messages.append({\"role\": \"user\", \"content\": question})\n        \n        try:\n            response = self.client.chat.completions.create(\n                model=self.model,\n                messages=self.messages,\n                temperature=0.7\n            )\n            \n            reply = response.choices[0].message.content\n            self.messages.append({\"role\": \"assistant\", \"content\": reply})\n            return reply\n            \n        except Exception as e:\n            return f\"请求失败: {e}\"\n    \n    def save_conversation(self, filename):\n        \"\"\"保存对话历史\"\"\"\n        with open(filename, 'w', encoding='utf-8') as f:\n            json.dump(self.messages, f, ensure_ascii=False, indent=2)\n    \n    def load_conversation(self, filename):\n        \"\"\"加载对话历史\"\"\"\n        with open(filename, 'r', encoding='utf-8') as f:\n            self.messages = json.load(f)\n\n# 使用示例\n# assistant = SmartAssistant(\"Python 编程\")\n# print(assistant.ask(\"列表和元组有什么区别？\"))\n# print(assistant.ask(\"给我一个使用场景的例子\"))\n```\n\n---\n\n## 流式输出\n\n### 为什么需要流式输出？\n\n```{mermaid}\nflowchart LR\n    subgraph \"普通输出\"\n        A1[\"发送请求\"] --> A2[\"等待 5-10秒\"]\n        A2 --> A3[\"一次性显示全部\"]\n    end\n    \n    subgraph \"流式输出\"\n        B1[\"发送请求\"] --> B2[\"立即开始显示\"]\n        B2 --> B3[\"逐字出现\"]\n    end\n```\n\n### 使用 OpenAI 库实现流式输出\n\n```{python}\n#| eval: false\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclient = OpenAI(\n    api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n    base_url=\"https://api.deepseek.com\"\n)\n\ndef chat_stream(message, system_prompt=\"你是一个助手\"):\n    \"\"\"流式对话\"\"\"\n    stream = client.chat.completions.create(\n        model=\"deepseek-chat\",\n        messages=[\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": message}\n        ],\n        stream=True  # 启用流式输出\n    )\n    \n    # 逐块输出\n    for chunk in stream:\n        if chunk.choices[0].delta.content:\n            print(chunk.choices[0].delta.content, end=\"\", flush=True)\n    \n    print()  # 换行\n\n# 使用示例\n# chat_stream(\"给我讲个笑话\")\n```\n\n### 收集完整响应\n\n```{python}\n#| eval: false\ndef chat_stream_with_result(message):\n    \"\"\"流式输出并返回完整结果\"\"\"\n    stream = client.chat.completions.create(\n        model=\"deepseek-chat\",\n        messages=[{\"role\": \"user\", \"content\": message}],\n        stream=True\n    )\n    \n    full_response = \"\"\n    for chunk in stream:\n        content = chunk.choices[0].delta.content or \"\"\n        print(content, end=\"\", flush=True)\n        full_response += content\n    \n    print()\n    return full_response\n\n# 使用示例\n# result = chat_stream_with_result(\"用三句话介绍 Python\")\n# print(f\"\\n完整响应长度：{len(result)} 字符\")\n```\n\n---\n\n## 课后作业\n\n### 作业 5 继续：期末综合项目\n\n**本周任务**：实现 AI 功能模块\n\n如果你的项目包含 LLM：\n1. 使用 OpenAI 库调用 DeepSeek API\n2. 设计 System Prompt\n3. 实现多轮对话\n4. 考虑是否需要流式输出\n\n**REPORT.md 记录**：\n- 你设计的 System Prompt 是什么？\n- 经过几次迭代优化？\n- AI 的回答质量如何评估？\n\n---\n\n## 本章小结\n\n- **多轮对话**：通过 messages 列表维护对话历史\n- **OpenAI 库**：简洁、类型安全、易于切换模型\n- **System Prompt**：定义角色、任务边界、输出格式\n- **Prompt Engineering**：Few-shot、思维链、结构化输出\n- **流式输出**：`stream=True` 改善用户体验\n\n```{mermaid}\nflowchart LR\n    A[\"LLM 应用开发\"] --> B[\"对话管理\"]\n    A --> C[\"Prompt 设计\"]\n    A --> D[\"输出优化\"]\n    \n    B --> B1[\"多轮对话\"]\n    B --> B2[\"历史管理\"]\n    \n    C --> C1[\"System Prompt\"]\n    C --> C2[\"Few-shot\"]\n    C --> C3[\"CoT\"]\n    \n    D --> D1[\"流式输出\"]\n    D --> D2[\"JSON 输出\"]\n```\n\n下一章，我们将学习 **Web 应用开发**——用 Streamlit 快速构建界面。\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":false,"toc-depth":3,"number-sections":true,"highlight-style":{"light":"github","dark":"dracula"},"output-file":"12-llm-basics.html"},"language":{"toc-title-document":"目录","toc-title-website":"该页面内容","related-formats-title":"其他格式","related-notebooks-title":"笔记本","source-notebooks-prefix":"资源","other-links-title":"其他链接","code-links-title":"代码链接","launch-dev-container-title":"启动 Dev Container","launch-binder-title":"启动 Binder","article-notebook-label":"文章笔记本","notebook-preview-download":"下载笔记本","notebook-preview-download-src":"下载源代码","notebook-preview-back":"返回文章","manuscript-meca-bundle":"MECA 存档","section-title-abstract":"摘要","section-title-appendices":"附录","section-title-footnotes":"脚注","section-title-references":"参考文献","section-title-reuse":"二次使用","section-title-copyright":"版权","section-title-citation":"引用格式","appendix-attribution-cite-as":"请按如下格式引用：","appendix-attribution-bibtex":"BibTeX","appendix-view-license":"查看许可协议","title-block-author-single":"作者","title-block-author-plural":"作者","title-block-affiliation-single":"单位","title-block-affiliation-plural":"单位","title-block-published":"发布于","title-block-modified":"修改于","title-block-keywords":"关键词","callout-tip-title":"提示","callout-note-title":"注记","callout-warning-title":"警告","callout-important-title":"重要","callout-caution-title":"注意","code-summary":"代码","code-tools-menu-caption":"代码","code-tools-show-all-code":"显示所有代码","code-tools-hide-all-code":"隐藏所有代码","code-tools-view-source":"查看源代码","code-tools-source-code":"源代码","tools-share":"Share","tools-download":"Download","code-line":"行","code-lines":"行","copy-button-tooltip":"复制到剪贴板","copy-button-tooltip-success":"已复制","repo-action-links-edit":"编辑该页面","repo-action-links-source":"查看代码","repo-action-links-issue":"反馈问题","back-to-top":"回到顶部","search-no-results-text":"没有结果","search-matching-documents-text":"匹配的文档","search-copy-link-title":"复制搜索链接","search-hide-matches-text":"隐藏其它匹配结果","search-more-match-text":"更多匹配结果","search-more-matches-text":"更多匹配结果","search-clear-button-title":"清除","search-text-placeholder":"","search-detached-cancel-button-title":"取消","search-submit-button-title":"提交","search-label":"搜索","toggle-section":"展开或折叠此栏","toggle-sidebar":"展开或折叠侧边栏导航","toggle-dark-mode":"切换深色模式","toggle-reader-mode":"切换阅读器模式","toggle-navigation":"展开或折叠导航栏","crossref-fig-title":"图","crossref-tbl-title":"表","crossref-lst-title":"列表","crossref-thm-title":"定理","crossref-lem-title":"引理","crossref-cor-title":"推论","crossref-prp-title":"命题","crossref-cnj-title":"猜想","crossref-def-title":"定义","crossref-exm-title":"例","crossref-exr-title":"习题","crossref-ch-prefix":"章节","crossref-apx-prefix":"附录","crossref-sec-prefix":"小节","crossref-eq-prefix":"式","crossref-lof-title":"图索引","crossref-lot-title":"表索引","crossref-lol-title":"列表索引","environment-proof-title":"证","environment-remark-title":"注记","environment-solution-title":"解","listing-page-order-by":"排序方式","listing-page-order-by-default":"默认","listing-page-order-by-date-asc":"日期升序","listing-page-order-by-date-desc":"日期降序","listing-page-order-by-number-desc":"降序","listing-page-order-by-number-asc":"升序","listing-page-field-date":"日期","listing-page-field-title":"标题","listing-page-field-description":"描述","listing-page-field-author":"作者","listing-page-field-filename":"文件名","listing-page-field-filemodified":"修改时间","listing-page-field-subtitle":"副标题","listing-page-field-readingtime":"阅读时间","listing-page-field-wordcount":"字数统计","listing-page-field-categories":"分类","listing-page-minutes-compact":"{0} 分钟","listing-page-category-all":"全部","listing-page-no-matches":"无匹配项","listing-page-words":"{0} 字","listing-page-filter":"筛选","draft":"草稿"},"metadata":{"lang":"zh","fig-responsive":true,"quarto-version":"1.8.14","bibliography":["../references.bib"],"theme":{"light":["cosmo","../theme.scss"],"dark":["darkly","../theme.scss"]},"code-copy":true,"number-depth":2,"smooth-scroll":true,"mermaid":{"theme":"neutral","mermaid-format":"svg"}},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"lualatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","toc":true,"number-sections":true,"output-file":"12-llm-basics.pdf"},"language":{"toc-title-document":"目录","toc-title-website":"该页面内容","related-formats-title":"其他格式","related-notebooks-title":"笔记本","source-notebooks-prefix":"资源","other-links-title":"其他链接","code-links-title":"代码链接","launch-dev-container-title":"启动 Dev Container","launch-binder-title":"启动 Binder","article-notebook-label":"文章笔记本","notebook-preview-download":"下载笔记本","notebook-preview-download-src":"下载源代码","notebook-preview-back":"返回文章","manuscript-meca-bundle":"MECA 存档","section-title-abstract":"摘要","section-title-appendices":"附录","section-title-footnotes":"脚注","section-title-references":"参考文献","section-title-reuse":"二次使用","section-title-copyright":"版权","section-title-citation":"引用格式","appendix-attribution-cite-as":"请按如下格式引用：","appendix-attribution-bibtex":"BibTeX","appendix-view-license":"查看许可协议","title-block-author-single":"作者","title-block-author-plural":"作者","title-block-affiliation-single":"单位","title-block-affiliation-plural":"单位","title-block-published":"发布于","title-block-modified":"修改于","title-block-keywords":"关键词","callout-tip-title":"提示","callout-note-title":"注记","callout-warning-title":"警告","callout-important-title":"重要","callout-caution-title":"注意","code-summary":"代码","code-tools-menu-caption":"代码","code-tools-show-all-code":"显示所有代码","code-tools-hide-all-code":"隐藏所有代码","code-tools-view-source":"查看源代码","code-tools-source-code":"源代码","tools-share":"Share","tools-download":"Download","code-line":"行","code-lines":"行","copy-button-tooltip":"复制到剪贴板","copy-button-tooltip-success":"已复制","repo-action-links-edit":"编辑该页面","repo-action-links-source":"查看代码","repo-action-links-issue":"反馈问题","back-to-top":"回到顶部","search-no-results-text":"没有结果","search-matching-documents-text":"匹配的文档","search-copy-link-title":"复制搜索链接","search-hide-matches-text":"隐藏其它匹配结果","search-more-match-text":"更多匹配结果","search-more-matches-text":"更多匹配结果","search-clear-button-title":"清除","search-text-placeholder":"","search-detached-cancel-button-title":"取消","search-submit-button-title":"提交","search-label":"搜索","toggle-section":"展开或折叠此栏","toggle-sidebar":"展开或折叠侧边栏导航","toggle-dark-mode":"切换深色模式","toggle-reader-mode":"切换阅读器模式","toggle-navigation":"展开或折叠导航栏","crossref-fig-title":"图","crossref-tbl-title":"表","crossref-lst-title":"列表","crossref-thm-title":"定理","crossref-lem-title":"引理","crossref-cor-title":"推论","crossref-prp-title":"命题","crossref-cnj-title":"猜想","crossref-def-title":"定义","crossref-exm-title":"例","crossref-exr-title":"习题","crossref-ch-prefix":"章节","crossref-apx-prefix":"附录","crossref-sec-prefix":"小节","crossref-eq-prefix":"式","crossref-lof-title":"图索引","crossref-lot-title":"表索引","crossref-lol-title":"列表索引","environment-proof-title":"证","environment-remark-title":"注记","environment-solution-title":"解","listing-page-order-by":"排序方式","listing-page-order-by-default":"默认","listing-page-order-by-date-asc":"日期升序","listing-page-order-by-date-desc":"日期降序","listing-page-order-by-number-desc":"降序","listing-page-order-by-number-asc":"升序","listing-page-field-date":"日期","listing-page-field-title":"标题","listing-page-field-description":"描述","listing-page-field-author":"作者","listing-page-field-filename":"文件名","listing-page-field-filemodified":"修改时间","listing-page-field-subtitle":"副标题","listing-page-field-readingtime":"阅读时间","listing-page-field-wordcount":"字数统计","listing-page-field-categories":"分类","listing-page-minutes-compact":"{0} 分钟","listing-page-category-all":"全部","listing-page-no-matches":"无匹配项","listing-page-words":"{0} 字","listing-page-filter":"筛选","draft":"草稿"},"metadata":{"block-headings":true,"lang":"zh","bibliography":["../references.bib"],"documentclass":"scrreprt","papersize":"a4","colorlinks":true},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}